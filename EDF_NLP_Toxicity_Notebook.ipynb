{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db032190",
   "metadata": {},
   "source": [
    "\n",
    "# **EDF R&D Digital Innovation – NLP Test (Détection de Toxicité)**\n",
    "_Auteur : <votre nom> — Généré le 2025-08-08 11:18 UTC_\n",
    "\n",
    "Ce notebook propose une solution reproductible et auto‑contenue pour classifier des commentaires en toxiques / non toxiques à partir du jeu de données `mteb/toxic_conversations_50k`.\n",
    "\n",
    "**Objectifs pédagogiques** :\n",
    "- Exploration et analyse de données\n",
    "- Pipelines de pré/post-traitement\n",
    "- Méthodologie d’évaluation (métriques & visualisations)\n",
    "- Construction et optimisation d’un modèle NLP (baseline + Transformer)\n",
    "- Analyse d’erreurs et interprétabilité\n",
    "- Organisation et lisibilité du code\n",
    "\n",
    "> Le dataset est exigeant. On optimise le processus plus que le score final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba1af0",
   "metadata": {},
   "source": [
    "## 1) Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c794c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Si vous êtes sur Colab, décommentez la ligne suivante :\n",
    "# %pip install -q -U datasets transformers accelerate evaluate scikit-learn imbalanced-learn nltk matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
    "                             average_precision_score, precision_recall_curve, roc_curve, f1_score)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae9b0d",
   "metadata": {},
   "source": [
    "## 2) Données — chargement & exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c785610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chargement des splits fournis\n",
    "dataset_train = load_dataset('mteb/toxic_conversations_50k', split='train')\n",
    "dataset_val   = load_dataset('mteb/toxic_conversations_50k', split='test')\n",
    "\n",
    "# Renommage pour clarté\n",
    "ds = DatasetDict({\n",
    "    \"train\": dataset_train,\n",
    "    \"validation\": dataset_val\n",
    "})\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conversion pandas pour EDA rapide\n",
    "df_train = ds[\"train\"].to_pandas()\n",
    "df_val   = ds[\"validation\"].to_pandas()\n",
    "\n",
    "print(df_train.head(3))\n",
    "print(df_train.describe(include='all'))\n",
    "print(\"\\nRépartition de classes (train) :\")\n",
    "print(df_train['label'].value_counts(normalize=True).rename({0:'non-toxique',1:'toxique'}))\n",
    "print(\"\\nRépartition de classes (val) :\")\n",
    "print(df_val['label'].value_counts(normalize=True).rename({0:'non-toxique',1:'toxique'}))\n",
    "\n",
    "# Longueurs de texte\n",
    "df_train['len'] = df_train['text'].str.split().apply(len)\n",
    "df_val['len']   = df_val['text'].str.split().apply(len)\n",
    "\n",
    "print(\"\\nLongueurs (mots) — train :\", df_train['len'].describe())\n",
    "print(\"Longueurs (mots) — val   :\", df_val['len'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661780b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histogramme des longueurs (train)\n",
    "plt.figure()\n",
    "df_train['len'].hist(bins=50)\n",
    "plt.xlabel(\"Longueur du commentaire (mots)\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"Distribution des longueurs (train)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b1f4a",
   "metadata": {},
   "source": [
    "## 3) Pré‑traitement minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    # Nettoyage léger pour la baseline classique.\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Appliquer le nettoyage pour la baseline TF‑IDF (on garde l'original pour le Transformer)\n",
    "df_train['text_clean'] = df_train['text'].apply(basic_clean)\n",
    "df_val['text_clean']   = df_val['text'].apply(basic_clean)\n",
    "\n",
    "X_train_clf = df_train['text_clean'].values\n",
    "y_train = df_train['label'].values\n",
    "X_val_clf   = df_val['text_clean'].values\n",
    "y_val   = df_val['label'].values\n",
    "\n",
    "print(\"Exemple (nettoyé):\", X_train_clf[0][:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7788c",
   "metadata": {},
   "source": [
    "## 4) Modèle 1 — Baseline (TF‑IDF + Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=2,\n",
    "    max_df=0.99,\n",
    "    strip_accents='unicode',\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Class weights\n",
    "classes = np.array([0,1])\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', classes=classes, y=y_train\n",
    ")\n",
    "cw = {cls: w for cls, w in zip(classes, class_weights)}\n",
    "print(\"Class weights:\", cw)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=200,\n",
    "    class_weight=cw,\n",
    "    solver='liblinear',\n",
    "    C=1.0\n",
    ")\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('ros', RandomOverSampler(random_state=RANDOM_SEED)),\n",
    "    ('clf', logreg),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_clf, y_train)\n",
    "\n",
    "# Probabilités & prédictions (seuil 0.5 initial)\n",
    "proba_val = pipeline.predict_proba(X_val_clf)[:,1]\n",
    "pred_val_05 = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_val, pred_val_05, digits=3))\n",
    "print(\"ROC‑AUC :\", roc_auc_score(y_val, proba_val))\n",
    "print(\"PR‑AUC  :\", average_precision_score(y_val, proba_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val_05)\n",
    "print(\"\\nMatrice de confusion (seuil 0.5):\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Courbes PR & ROC + choix de seuil par F1 max\n",
    "precision, recall, thr = precision_recall_curve(y_val, proba_val)\n",
    "f1s = 2*precision[:-1]*recall[:-1] / (precision[:-1]+recall[:-1] + 1e-9)\n",
    "best_idx = f1s.argmax()\n",
    "best_thr = thr[best_idx]\n",
    "print(f\"Seuil optimal (F1 max) : {best_thr:.3f} — F1={f1s[best_idx]:.3f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Courbe Precision‑Recall (baseline)\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, _ = roc_curve(y_val, proba_val)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"Courbe ROC (baseline)\")\n",
    "plt.show()\n",
    "\n",
    "# Évaluation au seuil optimisé\n",
    "pred_val_best = (proba_val >= best_thr).astype(int)\n",
    "print(\"\\n== Rapport au seuil optimisé ==\")\n",
    "print(classification_report(y_val, pred_val_best, digits=3))\n",
    "print(\"Matrice de confusion (seuil optimisé):\\n\", confusion_matrix(y_val, pred_val_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interprétabilité — top poids LogReg\n",
    "clf = pipeline.named_steps['clf']\n",
    "tfidf = pipeline.named_steps['vectorizer']\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "coefs = clf.coef_[0]\n",
    "\n",
    "top_pos_idx = np.argsort(coefs)[-20:][::-1]\n",
    "top_neg_idx = np.argsort(coefs)[:20]\n",
    "\n",
    "print(\"\\nTop 20 n‑grams associés à la classe TOXIQUE:\")\n",
    "for i in top_pos_idx:\n",
    "    print(f\"{feature_names[i]} \\t {coefs[i]:.3f}\")\n",
    "\n",
    "print(\"\\nTop 20 n‑grams associés à la classe NON‑TOXIQUE:\")\n",
    "for i in top_neg_idx:\n",
    "    print(f\"{feature_names[i]} \\t {coefs[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7596f",
   "metadata": {},
   "source": [
    "## 5) Modèle 2 — Fine‑tuning Transformer (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "from datasets import DatasetDict, Dataset\n",
    "tokenized_ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train[['text','label']]).map(tokenize_batch, batched=True),\n",
    "    \"validation\": Dataset.from_pandas(df_val[['text','label']]).map(tokenize_batch, batched=True),\n",
    "}).with_format(\"torch\")\n",
    "\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(DEVICE)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:,1].numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc_score(labels, probs),\n",
    "        \"pr_auc\": average_precision_score(labels, probs),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./outputs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"pr_auc\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_res = trainer.evaluate()\n",
    "print(eval_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbdf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Probabilités sur la validation + seuil optimisé (F1)\n",
    "import torch, numpy as np\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = []\n",
    "    for i in range(0, len(tokenized_ds[\"validation\"]), 128):\n",
    "        batch = tokenized_ds[\"validation\"][i:i+128]\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits.append(out.logits.cpu())\n",
    "    logits = torch.cat(logits, dim=0)\n",
    "\n",
    "probs = torch.softmax(logits, dim=1)[:,1].numpy()\n",
    "y_true = df_val['label'].values\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score, classification_report, confusion_matrix, roc_curve\n",
    "precision, recall, thr = precision_recall_curve(y_true, probs)\n",
    "f1s = 2*precision[:-1]*recall[:-1] / (precision[:-1]+recall[:-1] + 1e-9)\n",
    "best_idx = f1s.argmax()\n",
    "best_thr = thr[best_idx]\n",
    "print(f\"Seuil optimal (Transformer, F1 max) : {best_thr:.3f} — F1={f1s[best_idx]:.3f}\")\n",
    "print(\"ROC‑AUC :\", roc_auc_score(y_true, probs))\n",
    "print(\"PR‑AUC  :\", average_precision_score(y_true, probs))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Courbe Precision‑Recall (Transformer)\")\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"Courbe ROC (Transformer)\")\n",
    "plt.show()\n",
    "\n",
    "preds = (probs >= best_thr).astype(int)\n",
    "print(\"\\n== Rapport (Transformer, seuil optimisé) ==\")\n",
    "print(classification_report(y_true, preds, digits=3))\n",
    "print(\"Matrice de confusion :\\n\", confusion_matrix(y_true, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00517e99",
   "metadata": {},
   "source": [
    "## 6) Analyse d'erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff551c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "def top_errors(y_true, y_prob, k=10):\n",
    "    preds = (y_prob >= 0.5).astype(int)\n",
    "    fp_idx = np.where((preds==1) & (y_true==0))[0]\n",
    "    fn_idx = np.where((preds==0) & (y_true==1))[0]\n",
    "    fp_sorted = fp_idx[np.argsort(-y_prob[fp_idx])][:k]\n",
    "    fn_sorted = fn_idx[np.argsort(y_prob[fn_idx])][:k]\n",
    "    return fp_sorted, fn_sorted\n",
    "\n",
    "fp_ids, fn_ids = top_errors(y_true, probs, k=10)\n",
    "\n",
    "print(\"\\n--- Faux positifs (prédits toxiques, réalité non toxique) ---\")\n",
    "for i in fp_ids:\n",
    "    print(f\"[p={probs[i]:.3f}] {df_val['text'].iloc[i][:300]}\")\n",
    "\n",
    "print(\"\\n--- Faux négatifs (prédits non toxiques, réalité toxique) ---\")\n",
    "for i in fn_ids:\n",
    "    print(f\"[p={probs[i]:.3f}] {df_val['text'].iloc[i][:300]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a639a1",
   "metadata": {},
   "source": [
    "## 7) Export & inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae675f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib, os, torch\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "# Sauvegarde baseline\n",
    "joblib.dump(pipeline, \"artifacts/baseline_tfidf_logreg.joblib\")\n",
    "\n",
    "# Sauvegarde Transformer\n",
    "model.save_pretrained(\"artifacts/distilbert_toxic\")\n",
    "tokenizer.save_pretrained(\"artifacts/distilbert_toxic\")\n",
    "\n",
    "print(\"Artifacts sauvegardés dans ./artifacts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c16656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemple d'inférence\n",
    "sample_texts = [\n",
    "    \"I love this! Wonderful job, thanks for sharing.\",\n",
    "    \"You're an idiot. Get lost.\"\n",
    "]\n",
    "\n",
    "# Baseline\n",
    "X_sample = [basic_clean(t) for t in sample_texts]\n",
    "proba_base = pipeline.predict_proba(X_sample)[:,1]\n",
    "print(\"Baseline (probas toxiques):\", proba_base)\n",
    "\n",
    "# Transformer\n",
    "inputs = tokenizer(sample_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(**inputs)\n",
    "proba_transf = torch.softmax(out.logits, dim=1)[:,1].cpu().numpy()\n",
    "print(\"Transformer (probas toxiques):\", proba_transf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea22f08",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Conclusions (à adapter)\n",
    "- La baseline TF‑IDF + LogReg est rapide, interprétable et robuste.\n",
    "- Le Transformer (DistilBERT) capture mieux le contexte et améliore souvent PR‑AUC / ROC‑AUC.\n",
    "- Le seuil dépend du cas d’usage (prioriser précision ou rappel).\n",
    "- Pistes : loss focalisée, data augmentation, nettoyage avancé, MiniLM/BERT‑base selon budget, audit biais/fairness.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
